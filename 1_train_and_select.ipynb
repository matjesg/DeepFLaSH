{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1_train_and_select.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matjesg/DeepFLaSH/blob/master/1_train_and_select.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "cellView": "form",
        "colab_type": "code",
        "id": "LHGP8NywL-sT",
        "colab": {}
      },
      "source": [
        "#@title Set up Google Colab environment\n",
        "#@markdown Please run this cell to get started.\n",
        "%tensorflow_version 1.x\n",
        "#!pip install tensorflow-gpu==1.14\n",
        "!git clone https://github.com/matjesg/bioimage_analysis.git\n",
        "!pip install simpleITK\n",
        "%cd bioimage_analysis\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import keras.backend as K\n",
        "from unet import unet, preproc, lrfinder, utils\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "dnBXTRubeh7g"
      },
      "source": [
        "# Traing and model selection pipeline "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "nQ09MgFGeh7u"
      },
      "source": [
        "## Set parameters \n",
        "__Laboratory, consensus strategy, and model weights__\n",
        "- `LAB`: one of `inns1`, `inns2`, `mue`, `wue1`, `wue2`\n",
        "- `STRATEGY`: `consensus` or expert_x (e.g., `expert_1`) models\n",
        "- `PRETRAINED_WEIGHTS`: weights for model initialization (`None` for random initialization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "code",
        "id": "Vyt1jH3iL-sf",
        "colab": {}
      },
      "source": [
        "LAB = 'wue2'\n",
        "STRATEGY = 'consensus'\n",
        "PRETRAINED_WEIGHTS = None\n",
        "\n",
        "# Other parameters as used in our paper\n",
        "BATCH_SIZE = 4\n",
        "TILE_SHAPE = (540,540)\n",
        "PADDING = (184,184)\n",
        "\n",
        "# Loss weights calculation\n",
        "LAMBDA = 50 \n",
        "V_BAL = 0.1 \n",
        "SIGMA_BAL = 10 \n",
        "SIGMA_SEP = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "lDWXMLbyL-sr"
      },
      "source": [
        "## Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "code",
        "id": "MP_sx-K5eh79",
        "colab": {}
      },
      "source": [
        "DATA_PATH = \"train_data/lab-{}/images/\".format(LAB)\n",
        "MASK_PATH = \"train_data/lab-{}/labels/\".format(LAB)\n",
        "EXPERTS = [x for x in os.listdir(MASK_PATH) if x.startswith('expert')]\n",
        "LABEL_TYPE = os.listdir(os.path.join(MASK_PATH,EXPERTS[0]))[0].split('_')[1][:-4]\n",
        "\n",
        "# Get IDs\n",
        "file_ids = [x.rsplit('.',1)[0] for x in os.listdir(DATA_PATH)]\n",
        "\n",
        "# Load images\n",
        "images = [np.expand_dims(io.imread(os.path.join(DATA_PATH, x), as_gray=True), axis=2)\n",
        "          for x in [s + '.png' for s in file_ids]]\n",
        "\n",
        "# Load expert segmentation masks\n",
        "mask_dict = {}\n",
        "for exp in EXPERTS:\n",
        "    mask_dict[exp] = [io.imread(os.path.join(MASK_PATH, exp, x), as_gray=True).astype('int')//255 \n",
        "                      for x in [s + '_' + LABEL_TYPE + '.png' for s in file_ids]]\n",
        "\n",
        "# Load consensus (STAPLE)\n",
        "mask_dict['consensus'] = [io.imread(os.path.join(MASK_PATH, 'est_GT', x), as_gray=True).astype('int')//255 \n",
        "                          for x in [s + '_' + LABEL_TYPE + '.png' for s in file_ids]]\n",
        "\n",
        "## (Re-)compute consensus with simple ITK, if necassary\n",
        "# mask_dict['consensus'] = [utils.staple([mask_dict[exp][i] for exp in EXPERTS]) for i in range(len(file_ids))]\n",
        "\n",
        "# Create generator\n",
        "data = [{'rawdata': img, 'element_size_um': [1, 1]} for img in np.array(images)]\n",
        "gen = preproc.DataAugmentationGenerator(data = data, \n",
        "                                        classlabels=np.array(mask_dict[STRATEGY]),\n",
        "                                        tile_shape = TILE_SHAPE, \n",
        "                                        padding= PADDING,\n",
        "                                        batch_size = 2, # only for learning rate finder\n",
        "                                        n_classes=2,\n",
        "                                        rotation_range_deg=(0, 360),\n",
        "                                        flip=False,\n",
        "                                        deformation_grid=(150, 150),\n",
        "                                        deformation_magnitude=(10, 10),\n",
        "                                        value_minimum_range=(0, 0),\n",
        "                                        value_maximum_range=(0.0, 1),\n",
        "                                        value_slope_range=(1, 1),\n",
        "                                        shuffle=True,\n",
        "                                        foreground_dist_sigma_px=SIGMA_BAL,\n",
        "                                        border_weight_sigma_px=SIGMA_SEP,\n",
        "                                        border_weight_factor=LAMBDA,\n",
        "                                        foreground_background_ratio=V_BAL\n",
        "                                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "HbAY0CmoL-sw"
      },
      "source": [
        "## Training procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "true",
        "colab_type": "text",
        "id": "q3fUoNyVL-sx"
      },
      "source": [
        "1. Splitting the data into train and validation set (random stratified sampling)\n",
        "1. Determining the learning rate using the learning rate finder (Smith, 2018)\n",
        "1. Training the model with cyclical learning rates according to the fit-one-cycle policy of Smith (2018)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "bo6BUsMHL-sx"
      },
      "source": [
        "### Learning Rate Finder\n",
        "Examplary use, results may vary (see  Smith, (2018))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "code",
        "id": "KHmZO2wxL-sy",
        "colab": {}
      },
      "source": [
        "# Create model\n",
        "model = unet.Unet2D(snapshot=PRETRAINED_WEIGHTS)\n",
        "\n",
        "# Create and run Learning Rate Finder\n",
        "lrfind = lrfinder.LRFinder(model.trainModel)\n",
        "lrfind.find(gen, start_lr=1e-7, lr_mult=1.1, verbose=0)\n",
        "\n",
        "# Plot loss\n",
        "lrfind.plot_loss()\n",
        "\n",
        "# Free GPU Memory\n",
        "sess = K.get_session()\n",
        "K.clear_session()\n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "-YGTTxj_L-s2"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "We used \n",
        "- `SEED` to shuffle train-/validation data (defines the ensemble number, e.g. wue1_ __consensus2__ _model1 for `SEED=2`)) \n",
        "- stratified k-fold cross-validation (the fold later defines the model number, e.g. wue1_consensus2_ __model1__)\n",
        "- `max_lr = 5e-4` for _lab-wue1_ and `max_lr = 1e-4` for all other labs as maximum learning rate, according to the learning rate finder\n",
        "- a cycle length of 972 iterations (27 epochs)\n",
        "    - For faster computation, we randomly sampled 9 (_lab-wue1_) or 36 (other labs) tiles from each augmented image in each epoch\n",
        "\n",
        "We predicted validation images from the saved model weights after each epoch for the post-hoc evaluation. Validation during training was based on image tiles only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "code",
        "id": "8gnp7u6zL-s3",
        "colab": {}
      },
      "source": [
        "SEED = 1\n",
        "skf = StratifiedKFold(n_splits= 4 if LAB == 'wue1' else 5, \n",
        "                      random_state=SEED, shuffle=True)\n",
        "\n",
        "# Define properties for stratified sampling\n",
        "if LAB == 'wue1': \n",
        "    strata = pd.read_csv('train_data/lab-wue1/groups_wue1.csv', dtype='str')\n",
        "else: \n",
        "    strata = pd.DataFrame({'file_id': file_ids, 'group_id':0})\n",
        "\n",
        "pred_dict = {}\n",
        "fold = 0\n",
        "for train_index, val_index in skf.split(strata['file_id'], strata['group_id']):\n",
        "    fold += 1\n",
        "    name = LAB + '_' + STRATEGY + str(SEED) + '_' + str(fold) \n",
        "    print(name)\n",
        "    \n",
        "    # Split training and validation data\n",
        "    X_train_cv, X_val_cv = np.array(images)[train_index], np.array(images)[val_index]\n",
        "    masks = mask_dict[STRATEGY]\n",
        "    y_train_cv, y_val_cv = np.array(masks)[train_index], np.array(masks)[val_index]\n",
        "    W_train_cv = np.array(gen.weights)[train_index]\n",
        "    data_train_cv = [{'rawdata': img, 'element_size_um': [1, 1]} for img in X_train_cv]\n",
        "    data_val_cv = [{'rawdata': img, 'element_size_um': [1, 1]} for img in X_val_cv]\n",
        "\n",
        "    # Create train generator\n",
        "    train_generator = preproc.DataAugmentationGenerator(data = data_train_cv, \n",
        "                                                classlabels=y_train_cv,\n",
        "                                                instancelabels=None,\n",
        "                                                tile_shape = TILE_SHAPE, \n",
        "                                                padding= PADDING,\n",
        "                                                batch_size = 4,\n",
        "                                                n_classes=2,\n",
        "                                                ignore=None,\n",
        "                                                weights=list(W_train_cv),\n",
        "                                                element_size_um=None,\n",
        "                                                rotation_range_deg=(0, 360),\n",
        "                                                flip=False,\n",
        "                                                deformation_grid=(150, 150),\n",
        "                                                deformation_magnitude=(10, 10),\n",
        "                                                value_minimum_range=(0, 0),\n",
        "                                                value_maximum_range=(0.0, 1),\n",
        "                                                value_slope_range=(1, 1),\n",
        "                                                shuffle=True,\n",
        "                                                foreground_dist_sigma_px=SIGMA_BAL,\n",
        "                                                border_weight_sigma_px=SIGMA_SEP,\n",
        "                                                border_weight_factor=LAMBDA,\n",
        "                                                foreground_background_ratio=V_BAL)\n",
        "    # Create validation generator\n",
        "    tile_generator_val = preproc.TileGenerator(data_val_cv, TILE_SHAPE, PADDING, \n",
        "                                           classlabels=y_val_cv,\n",
        "                                           foreground_dist_sigma_px=SIGMA_BAL,\n",
        "                                           border_weight_sigma_px=SIGMA_SEP,\n",
        "                                           border_weight_factor=LAMBDA,\n",
        "                                           foreground_background_ratio=V_BAL)\n",
        "    \n",
        "    # Create model\n",
        "    model = unet.Unet2D(snapshot=PRETRAINED_WEIGHTS, name=name)\n",
        "\n",
        "    # Fit model\n",
        "    model.fit_one_cycle(train_generator, \n",
        "                        max_lr = 5e-4 if LAB == 'wue1' else 1e-4,\n",
        "                        final_epoch = 12 if LAB == 'wue1' else 27,\n",
        "                        validation_generator= tile_generator_val, \n",
        "                        snapshot_dir = '_cp/fold'+str(fold),\n",
        "                        snapshot_prefix=name,\n",
        "                        step_muliplier=9 if LAB == 'wue1' else 36)\n",
        "\n",
        "    # Free GPU Memory\n",
        "    sess = K.get_session()\n",
        "    K.clear_session()\n",
        "    sess.close()\n",
        "\n",
        "    # Get checkpoint names\n",
        "    cps = sorted([x for x in os.listdir('_cp/fold'+str(fold)) if x.startswith(name)])\n",
        "    file_ids_val = list(np.array(file_ids)[val_index])\n",
        "\n",
        "    # Predict validation images for post-hoc evaluation\n",
        "    for cp in sorted(cps):\n",
        "        print(cp)\n",
        "        pred_model = unet.Unet2D(snapshot=os.path.join('_cp/fold'+str(fold), cp))\n",
        "        predictions = pred_model.predict(tile_generator_val)   \n",
        "        for i, idx in enumerate(file_ids_val):           \n",
        "            pred_dict[(cp, idx)] = predictions[1][i]\n",
        "        \n",
        "        # Free GPU Memory\n",
        "        sess = K.get_session()\n",
        "        K.clear_session()\n",
        "        sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "xallCZxjL-s7"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "2mipZoCbL-s8"
      },
      "source": [
        "Selecting the model with the highest F1 score on the validation set. We used\n",
        "- `MIN_PIXEL` to approximate the minimum biologically justifiable size based on the smallest area that was annotated by a human expert \n",
        "- `IOU_t=0.5` as IoU threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "code",
        "id": "80er644PL-s9",
        "colab": {}
      },
      "source": [
        "MIN_PIXEL = {'inns1':16, 'inns2':60, 'mue':30, 'wue1':30, 'wue2':112}\n",
        "IOU_t=0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "jVpo2oXtL-tC"
      },
      "source": [
        "__Similarity analysis and model selection__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "code",
        "id": "SFH8gkL8L-tC",
        "colab": {}
      },
      "source": [
        "res_list = []\n",
        "for i, idx in enumerate(file_ids):\n",
        "    # Exclude area from analysis (wue2 only)\n",
        "    if LAB == 'wue2':\n",
        "        exclude = [io.imread(os.path.join(\"train_data/lab-wue2/ignored_regions/\", x), as_gray=True)//255 for \n",
        "                   x in [idx + '_ignore.png' for s in file_ids]]\n",
        "        for exp in EXPERTS+['consensus']:\n",
        "            mask_dict[exp][i][exclude[i]==1]=0\n",
        "        for cp, idx2 in pred_dict:\n",
        "            if idx==idx2:\n",
        "                pred_dict[(cp, idx)][exclude[i]==1]=0\n",
        "\n",
        "    # Label connected regions\n",
        "    label_a = utils.label_mask(mask_dict['consensus'][i], min_pixel=MIN_PIXEL[LAB])\n",
        "    for exp in EXPERTS:\n",
        "        # Label connected regions\n",
        "        label_b =  utils.label_mask(mask_dict[exp][i], min_pixel=MIN_PIXEL[LAB])\n",
        "        # Match ROIs\n",
        "        tmp_res =  utils.iou_mapping(label_a, label_b, min_roi_size=MIN_PIXEL[LAB])\n",
        "        df_exp = pd.Series({'FileId' : idx,\n",
        "                            'Type': 'ref',\n",
        "                              'cp_name' : exp,\n",
        "                              'count_a': tmp_res[3], \n",
        "                              'count_b': tmp_res[4], \n",
        "                              'matches_iou' : tmp_res[0]})\n",
        "        res_list += [df_exp]\n",
        "    for cp, idx2 in pred_dict:\n",
        "        if idx==idx2:\n",
        "            # Label connected regions\n",
        "            label_b =  utils.label_mask(pred_dict[(cp, idx)], min_pixel=MIN_PIXEL[LAB])\n",
        "            # Match ROIs\n",
        "            tmp_res =  utils.iou_mapping(label_a, label_b, min_roi_size=MIN_PIXEL[LAB])\n",
        "            df_pred = pd.Series({'FileId' : idx,\n",
        "                                'Type': 'pred',\n",
        "                                  'cp_name' : cp,\n",
        "                                  'count_a': tmp_res[3], \n",
        "                                  'count_b': tmp_res[4], \n",
        "                                  'matches_iou' : tmp_res[0]})\n",
        "            res_list += [df_pred]\n",
        "            \n",
        "# Compute precision, recall, and F1 score\n",
        "df = pd.DataFrame(res_list)\n",
        "df['fold'] = df['cp_name'].str[-9:-8]\n",
        "df['matches'] =  df['matches_iou'].apply(lambda x : x[x>IOU_t].shape[0] if len(x)>0 else 0)\n",
        "df['precision'] =  df.matches/df.count_a\n",
        "df['recall'] = df.matches/df.count_b\n",
        "df['f1_score'] = 2 * (df.precision * df.recall) / (df.precision + df.recall)\n",
        "\n",
        "# # filter models below expert reference lower bound\n",
        "exp_lb = df[df.Type=='ref'].groupby('FileId').f1_score.min()\n",
        "exp_lb.name = 'f1_lb'\n",
        "df_pred = df[df.Type=='pred'].join(exp_lb, on='FileId')\n",
        "#df_pred = df_pred[df_pred.f1_lb<df_pred.f1_score]\n",
        "\n",
        "# select models with highest f1 score (f1 score median)\n",
        "df_select = (df_pred.groupby(['fold', 'cp_name'])\n",
        "             .f1_score.agg(['median', 'count'])\n",
        "             .reset_index('cp_name')\n",
        "             .sort_values('median')\n",
        "             .groupby(['fold'])\n",
        "             .first().reset_index())\n",
        "df_select = df_select[df_select['count']==len(val_index)]\n",
        "df_select['ensemble_model_number'] = df_select.cp_name.str[:-9]+'model'+df_select.fold\n",
        "\n",
        "# Print models selected for ensembling\n",
        "df_select[['cp_name', 'ensemble_model_number']]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}